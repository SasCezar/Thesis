\chapter{Introduction}
\paragraph{}
With the diffusion of Internet, the Web 2.0, and the mobile devices the amount of data generated grows exponentially. A large amount of this data are generated by users. As shown by \href{http://www.internetlivestats.com/}{www.internetlivestats.com} each day 500 million tweets are sent and 5 million of blog post are written. The problem with these articles and posts is that they are not structured and this mean that we cannot use these data to generate information. The field of computer science that tries to generate information from unstructured data is called Information Extraction (IE). In most cases IE concerns of processing human language text using Natural Language Processing (NLP) techniques.
\section{Information Extraction}
IE can be separated in many sub-tasks based on the data required to process. Typically the main sub-tasks are:
\begin{itemize}[topsep=10pt]
\item Named Entity rEcognition and Linking (NEEL): which is composted by a Named Entity Recognition (NER) system and a Named Entity Linking (NEL) system. The NER goal is to find all the named entity contained in the text. The NEL takes the named entities and links them to the KB. A named entity is a real-world object such as persons, locations, organizations, products, etc., that can be denoted with a proper name.
\item Relationship extraction: finding the relations between entities in a phrase. For example for the sentence "Elon lives in California" we can extract "PERSON located in LOCATION".
\pagebreak
\item Terminology extraction: finding the relevant terms in a text or more generally in a corpus.
\end{itemize}

For the scope of this thesis we will focus only on the NEEL task (more precisely on the linking part).
\section{NEEL}
\subsection{NER}
\paragraph{}
Named Entity Recognition is a critical IE task, as it identifies which terms in a text are mentions of entities in the real world. The NER is also a pre-requisite not only for NEL but also for other IE task, including co-reference resolution, and relation extraction.

\paragraph{}
As we mentioned before user content are one of the biggest source of data, specifically platforms of micro-blogging like Facebook and Twitter. Early experiments have showed this genre to be extremely challenging for state-of-the-art algorithms of IE~\cite{derczynski2013microblog}. For instance, NER methods typically have around 90\% of accuracy on longer texts, but only 35-50\% over micro-blog post like tweets. The problems could be summarized as follows:

\begin{itemize}
\item Shortness of micro-blogs: the max length of a tweet is 140 characters and this makes them hard to interpret.
\item Capitalization of the words: in a tweet, or any other micro-blog post, the capitalization of words is ignored for increasing the speed of writing. The user could also deliberately overdo them with the intent of adding more emphasis to the message. This is a problem as some words change their meaning based on the capitalization of the letter. For example "trump" and "Trump" in a tweet could both be refereed to the president of the USA but for a musician the first one reefers to a musical instrument and the second one to the president.
\item Word Typos: as for the capitalization a typo could significantly change the meaning of a word. In micro-blogs posts the amount of typos is 2.5 times greater than in a well-formed text~\cite{derczynski2015analysis}.
\item Abbreviations: given the limit on the number of characters, users tend to use abbreviations in order to write more expressive messages in the same amount of space.
\item Emotions: the meaning of a sentence can be drastically changed by an emoji.
\end{itemize}
\paragraph{}
To overcome these problems the researchers have focuses on specific NERs for micro-blogs posts (eg Named Entity Recognition for Twitter using CRF by Ritter et. al~\cite{ritter2011named}).
\subsection{NEL}
- DISAMBIGUATION\\
- PROBLEMS OF CONTEXT
\section{Knowledge Base}
TO-DO

\section{Word Embeddings}
\subsection{Word2Vec}