\chapter{State of the Art}
In this chapter we will introduce a quick summary of the state-of-the-art techniques in entity linking based on the survey of Shen et al.~\cite{shen2015entity}.
\paragraph{}
The researchers of \cite{shen2015entity} divide the main task in three modules:
\begin{itemize}
\item Candidate entity generation: This module extract for each entity mention a set of candidates which may contain the correct one.
\item Candidate entity ranking: Its task is to find the most likely link for the mention in the list of the candidates.
\item NIL prediction: Some mentions could not have a link, this module checks if the best candidate from the previous module is the target for the mention. 
\end{itemize}

\section{Candidates Generation}
\paragraph{}
Formally, the candidate entity generation can be described as follows:
\[\forall m \in M \; find \; E_m\]
Where:

\begin{itemize}[noitemsep,  topsep=10pt]
\item $m$ is the entity mention
\item $M$ is the set of all mentions
\item $E_m$ is the set of candidate entities for m
\end{itemize}

TO DO - Intro to the next paragraph

\paragraph{}
We can classify these techniques in three groups:
\begin{itemize}[noitemsep,  topsep=10pt]
\item Name Dictionary based techniques
\item Search Engine based techniques
\item Machine Learning based techniques
\end{itemize}

\subsection{Name Dictionary Techniques}
\paragraph{}
The structure of Wikipedia provides a useful feature for generating candidate entities, like entity pages, redirect pages, disambiguation pages and hyperlinks in Wikipedia articles. These type of entity linking system use different combination of these feature to build an offline dictionary $D$ between entity name and possible mapping entities. Then the entity is compared with the dictionary's keys, the corresponding value, if the key exist, is list of candidates for the entity. The key entity comparison can be made using exact matching or partial matching. 

\paragraph{}
This approach is used by KEA~\cite{waitelonisnamed} where they map each token to a gazetteer compiled from the DBPedia entities labels, redirect labels, and disambiguation labels being mapped to the correct DBPedia entities. For the candidate generation KEA uses an exact matching  after normalizing the entity. They also resolve overlapping token by preferring the longer tokens over short ones.

\paragraph{}
Even if name dictionary is the main technique used by many entity linking systems it has some limitation. A dictionary structure cannot represent the semantic similarity between words. Its concept of similarity between words is the value of each key, so if a word is in the list then is similar otherwise no. This problem is partially solved in systems that use search engines. 

\subsection{Search Engine Techniques}
\paragraph{}
Some entity linking systems are trying to use the whole web information for candidate generation, they uses Web search engines for retrieving the list of candidates associated to the entity.

\paragraph{}
An example of this is the system proposed by Han and Zhao~\cite{han2009nlpr_kbp} where they submit a query containing the entity and its context to the Google API and obtained only the Wikipedia pages which are used as candidates. A similar method is used by Dredze et al.~\cite{dredze2010entity}, in this case they used as candidate list only the Wikipedia result in the top 20 Google search results. As determinated by Lehmann et al.~\cite{lehmann2010lcc} and Monahan et al.~\cite{monahan2011cross} Google search engine is very effective in resolving mappings between entity and surface form.

\paragraph{}
A different approach is used by UniMiB~\cite{caliano2016unimib}, is this case they built an index using Apache Lucene on the title ($rdf:label$), extended abstract\break($dbpedia:abstract$), type ($dbo:type$), PageRank, and url from DBpedia. Then for candidate extraction they query Lucene using the mention and obtain a list of the documents in which the mention is contained.

\paragraph{}
As we mentioned previously, search engines resolve partially the problem of semantic similarity, this is because they analyze pages and consider the co-occurrence of two words~\cite{bollegala2007measuring}, if two words have high co-occurrence they may have similar meaning. This is a very naive approach but it gives us the idea of how a search engine could implement semantic similarity. This problem can be solved using machine learning algorithms, in particular we will see an implementation using neuronal networks. 

\subsection{Machine Learning Techniques}
\paragraph{}
Machine learning algorithms are increasingly present in every field of computer science. Clustering algorithms, Bayesian networks and neural networks are now the state-of-the-art approach in many fields, NLP makes no exception.

UNIBA??? - NO

\section{Candidates Ranking}
\paragraph{}
After the candidates extraction, defined in the previous section, we need to rank the candidates. The ranking process can be defined as follows:
\[\forall e_m \in E_m \; rank(e_m)\]
Where:

\begin{itemize}[noitemsep,  topsep=10pt]
\item $e_m$ is a candidate entity for the mention m
\item $E_m$ is the set of candidate entities for m
\item $rank(e_m)$ is a function that calculates the score of the candidate
\end{itemize}

\paragraph{}
The $rank$ function can be defined in many ways, and use different features and techniques for calculating the final score so, before we analyze the different techniques, is important to understand the various types of features used.

\subsection{Features}
A feature

\subsection{Techniques} 
another text

\section{NIL Prediction}
\paragraph{}
Some entity mentions might not have a corresponding record in the KB, therefore we have to deal with the problem of predicting unlinkable mentions. 